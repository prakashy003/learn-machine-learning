{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb3b0fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fruit_feature'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfruit_feature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_features\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# load the training dataset\u001b[39;00m\n\u001b[0;32m      9\u001b[0m train_path  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124map-or-database/train\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fruit_feature'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn import tree\n",
    "from fruit_feature import extract_features\n",
    "\n",
    "# load the training dataset\n",
    "train_path  = \"ap-or-database/train\"\n",
    "train_names = os.listdir(train_path)\n",
    "\n",
    "# empty list to hold feature vectors and train labels\n",
    "train_features = []\n",
    "train_labels   = []\n",
    "\n",
    "# loop over the training dataset\n",
    "for train_name in train_names:\n",
    "\tcur_path = train_path + \"/\" + train_name\n",
    "\tcur_label = train_name\n",
    "\ti = 1\n",
    "\n",
    "\tfor file in glob.glob(cur_path + \"/*.jpg\"):\n",
    "\t\tprint (\"Processing Image - {} in {}\".format(i, cur_label))\n",
    "\t\t# read the training image\n",
    "\t\timage = cv2.imread(file)\n",
    "\n",
    "\t\t# extract texture and color from the image\n",
    "\t\tfeatures = extract_features(image)\n",
    "\n",
    "\t\t# append the feature vector and label\n",
    "\t\ttrain_features.append(features)\n",
    "\t\ttrain_labels.append(cur_label)\n",
    "\n",
    "\t\t# show loop update\n",
    "\t\ti += 1\n",
    "\n",
    "\n",
    "# create the classifier\n",
    "clf=tree.DecisionTreeClassifier()\n",
    "\n",
    "# train the classifier\n",
    "print (\"Training model..\")\n",
    "clf.fit(train_features, train_labels)\n",
    "\n",
    "# loop over the test images\n",
    "test_path = (\"ap-or-database/test\")\n",
    "for file in glob.glob(test_path + \"/*.jpg\"):\n",
    "\t# read the input image\n",
    "    image = cv2.imread(file)\n",
    "\n",
    "\t\t# extract texture and color from the image\n",
    "    features = extract_features(image)\n",
    "\n",
    "\t# evaluate the model and predict label\n",
    "    prediction = clf.predict(features.reshape(1, -1))[0]\n",
    "\n",
    "\t# show the label\n",
    "    cv2.putText(image, prediction, (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (235,188,0), 3)\n",
    "    print (\"Prediction - {}\".format(prediction))\n",
    "\n",
    "\t# display the output image\n",
    "    cv2.imshow(\"Test_Image\", image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f28c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
